{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpdG99uzA_IN"
   },
   "source": [
    "**Purpose:**\n",
    "This notebook consists of profiling of the python applications and scripts that we developed for the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYuvpb2BCLzr"
   },
   "outputs": [],
   "source": [
    "!pip install face_recognition\n",
    "!pip install facenet_pytorch\n",
    "!pip install mmcv\n",
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuKTGOu5A_IY",
    "outputId": "afaf13bd-d747-40c8-b320-caca0d3e9d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import cupy as cp\n",
    "from time import time\n",
    "%load_ext line_profiler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWY0mHJSA_Ib",
    "outputId": "8b01a801-341b-41c8-a4a4-31fad7d2af63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "run_on_colab = True\n",
    "if run_on_colab:\n",
    "    from google.colab import drive\n",
    "  \n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    path = \"/content/drive/My Drive/AdvancedPython2021\"\n",
    "else:\n",
    "    path = os.getcwd()\n",
    "os.chdir(path)\n",
    "from array_mp4_conversion import array_to_mp4, mp4_to_array\n",
    "file = \"girl.gif\"\n",
    "data_path = os.path.join(path, \"data\", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "id": "QAfO0x-2A_Ib"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from array_mp4_conversion import array_to_mp4, mp4_to_array\n",
    "from numba import jit, prange, cuda\n",
    "from collections import defaultdict\n",
    "from scipy.signal import convolve2d\n",
    "# cimport numpy as np\n",
    "# ctypedef np.uint8_t D_TYPE\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "class video_transformer_base:\n",
    "    '''\n",
    "    This is the base of video_transformer, containing basic information about the video.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                path, \n",
    "                save_path, \n",
    "                file_name, \n",
    "                device='cpu',\n",
    "                display=False):\n",
    "        \n",
    "        self.video_path = os.path.join(path, \"data\", file_name)\n",
    "        self.video_array, self.fps = mp4_to_array(self.video_path)\n",
    "        self.display = display\n",
    "        self.save_path = save_path\n",
    "        self.file_name = file_name\n",
    "        self.num_frames = 0\n",
    "        if device == 'cpu':\n",
    "            self.device = 'cpu'\n",
    "        else:\n",
    "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    def main_transformation(self, \n",
    "                            face_detection_model, \n",
    "                            filter_effect):\n",
    "        '''\n",
    "        For each frame, do:\n",
    "        1. detect the face;\n",
    "        2. apply the filter;\n",
    "        3. save the processed frame.\n",
    "        '''                    \n",
    "        video_capture = cv2.VideoCapture(self.video_path)\n",
    "        frame_count = 0\n",
    "        output_frames = []\n",
    "        while video_capture.isOpened():    \n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            # Bail out when the video file ends\n",
    "            if not ret:\n",
    "                video_capture.release()\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "            # detect faces\n",
    "            if face_detection_model != \"mtcnn\":\n",
    "                face_locations = self.face_detection(frame, \n",
    "                                                     model=face_detection_model)\n",
    "            else:\n",
    "                face_locations = self.face_detection_mtcnn(frame)\n",
    "\n",
    "            # add effect\n",
    "            after_effect_frame = filter_effect(frame, face_locations)\n",
    "\n",
    "            if self.display and frame_count % 2 == 0:\n",
    "               # If faces were found, we will mark it on frame with blue dots\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                plt.imshow(after_effect_frame)\n",
    "                plt.show()\n",
    "                clear_output(wait=True)\n",
    "\n",
    "            output_frames.append(after_effect_frame)\n",
    "        self.num_frames = frame_count\n",
    "        self.des_arr = np.array(output_frames)\n",
    "\n",
    "    def face_detection(self, frame):\n",
    "        '''\n",
    "        Face detection with package face_recognition.\n",
    "        Models includes: svm, knn, cnn.\n",
    "        Currently fixed as model='svm' because model ='cnn' is slow.\n",
    "        '''\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_frame, model='svm')\n",
    "        # print(f\"{len(face_locations)} face(s) detected.\")\n",
    "        \n",
    "        return face_locations\n",
    "    def face_detection_mtcnn(self, frame):\n",
    "        '''\n",
    "        Face detection with package facenet_pytorch.\n",
    "        MTCNN implemented in Pytorch, so also support CUDA.\n",
    "        '''       \n",
    "\n",
    "        mtcnn = MTCNN(keep_all=True, device=self.device)\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "            \n",
    "        boxes = np.array([[box[1], box[2], box[3], box[0]] for box in boxes]).astype(np.int)\n",
    "        # print(f\"{len(boxes)} face(s) detected.\")\n",
    "        return boxes\n",
    "    def oil_effect(self, frame):\n",
    "        '''\n",
    "        Please refer to unused_oil_effect.py for implementation.\n",
    "        '''\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def negative_effect(self, frame, locations):\n",
    "        '''\n",
    "        Apply negative filter effect to target locations.\n",
    "        '''\n",
    "        des_img = np.copy(frame)\n",
    "        try:\n",
    "            for location in locations:\n",
    "                t_, r_, b_, l_ = location.astype(int)\n",
    "\n",
    "                des_img[t_:b_,l_:r_] = 255 - frame[t_:b_,l_:r_]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img\n",
    "\n",
    "    def mean_blur(self, frame, locations, radius=5):\n",
    "        '''\n",
    "        Apply simple mosaic effect to specified regions. \n",
    "        '''\n",
    "        k = 1 / (radius*2+1)**2\n",
    "        des_img = np.copy(frame)\n",
    "        height, width, _ = des_img.shape\n",
    "\n",
    "        for location in locations:\n",
    "            top, right, bottom, left = location\n",
    "            t_ = max(top+radius,0)\n",
    "            b_ = min(bottom-radius, height)\n",
    "            l_ = max(left+radius,0)\n",
    "            r_ = min(right-radius, width)\n",
    "            if t_ >= b_ or l_ >= r_:\n",
    "                continue\n",
    "\n",
    "            for i, j in product(range(t_, b_), range(l_, r_)):\n",
    "                kernel = frame[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
    "                sumed = np.sum(kernel, axis = (0,1)) * k\n",
    "                des_img[i, j] = sumed.astype(np.uint8)\n",
    "\n",
    "        \n",
    "        return des_img    \n",
    "    \n",
    "    def write_to_video(self, output_filename):\n",
    "        '''\n",
    "        Write out the video with filter to mp4.\n",
    "        '''\n",
    "        array_to_mp4(output_filename, self.des_arr, self.fps)\n",
    "\n",
    "class video_transformer_parallel(video_transformer_base):\n",
    "    '''\n",
    "    This version views the video as an array for easier parallelization.\n",
    "    '''\n",
    "    def __init__(self, path, save_path, file_name, device='cpu',display=False):\n",
    "        video_transformer_base.__init__(self, path, save_path, file_name, \n",
    "                                        device, display)\n",
    "        \n",
    "        self.locations = None\n",
    "        self.des_arr = None\n",
    "\n",
    "        torch.from_numpy(self.video_array).to(self.device)    \n",
    "   \n",
    "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
    "        '''\n",
    "        Apply filter on the video.\n",
    "        '''\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "        radius_list = [radius] * frame_size\n",
    "\n",
    "        list(map(filter_func, self.video_array, self.des_arr, self.locations, radius_list))\n",
    "        \n",
    "    def filter_on_video_cuda(self, img_blur_cuda, radius=10, face_detection_model = 'mtcnn'):\n",
    "        '''\n",
    "        Filter on entire video using CUDA for blurring. It specifies block size and controls bounds.\n",
    "        '''\n",
    "        blocksize = (32,32)\n",
    "        k = 1 / (2*radius+1)**2\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "        np.save(\"frame_test.out\", self.des_arr[20])\n",
    "        np.save(\"locations_tests.out\", self.locations[20])\n",
    "        for i in range(frame_size):\n",
    "            for location in self.locations[i]:\n",
    "                top, right, bottom, left = location\n",
    "                face = np.ascontiguousarray(self.des_arr[i, top:bottom+1, left:right+1, :])\n",
    "                gridsize = (face.shape[0]//blocksize[0]+1, face.shape[1]//blocksize[1]+1)\n",
    "                blur_face = np.empty_like(face)\n",
    "                img_blur_cuda[gridsize, blocksize](face, blur_face, k, radius)\n",
    "                self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
    "    \n",
    "    def filter_on_video_cv2(self, cv2_blur, radius=10, face_detection_model = 'mtcnn'):\n",
    "        '''\n",
    "        Filter on entire video using CV2.blur.\n",
    "        '''\n",
    "        k = 1 / (2*radius+1)**2\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "        \n",
    "        for i in range(frame_size):\n",
    "            for location in self.locations[i]:\n",
    "                top, right, bottom, left = location\n",
    "                face = self.des_arr[i, top:bottom+1, left:right+1, :]\n",
    "                blur_face = np.empty_like(face)\n",
    "                cv2_blur(src=face, dst=blur_face, ksize=(radius,radius))\n",
    "                self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face   \n",
    "\n",
    "    def filter_on_video_face_only(self, filter_func, radius=10, face_detection_model = 'mtcnn'):\n",
    "        '''\n",
    "        Filter on the entire video, but the filter function only take in the face regions \n",
    "        instead of the entire frame to reduce data size.\n",
    "        '''\n",
    "        k = 1 / (2*radius+1)**2\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "\n",
    "        for i in range(frame_size):\n",
    "            for location in self.locations[i]:\n",
    "                top, right, bottom, left = location\n",
    "                face = self.des_arr[i, top:bottom+1, left:right+1, :]\n",
    "                blur_face = np.empty_like(face)\n",
    "                blur_face = filter_func(face=face, blur_face=blur_face, radius=radius)\n",
    "                self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face   \n",
    "    \n",
    "    def mean_blur_convolution(self, image, des_img, locations, radius):\n",
    "        '''\n",
    "        Utilized Scipy convolution to perform blurring effect on faces in one frame.\n",
    "        '''\n",
    "        if len(locations) == 0:\n",
    "              print(\"No faces\")\n",
    "              return\n",
    "          # print(len(locations))\n",
    "        n_neighbor = radius*2+1\n",
    "        height, width, _ = des_img.shape\n",
    "        kernel = np.ones((n_neighbor, n_neighbor))\n",
    "        for (top, right, bottom, left) in locations:\n",
    "            t_ = max(top+radius,0)\n",
    "            b_ = min(bottom-radius, height)\n",
    "            l_ = max(left+radius,0)\n",
    "            r_ = min(right-radius, width)\n",
    "\n",
    "            if t_ >= b_ or l_ >= r_:\n",
    "                continue\n",
    "            sample_area = image[t_-radius:b_+radius+1, l_-radius:r_+radius+1,:].astype(np.uint8)\n",
    "            \n",
    "            # np.save(\"face.out\", sample_area)\n",
    "            red = convolve2d(sample_area[:,:,0], kernel, 'same')\n",
    "            green = convolve2d(sample_area[:,:,1], kernel, 'same')\n",
    "            blue = convolve2d(sample_area[:,:,2], kernel, 'same')\n",
    "\n",
    "            convol_area = np.stack([red, green, blue], axis=2)\n",
    "\n",
    "            des_img[t_-radius:b_+radius+1, l_-radius:r_+radius+1,:] = (convol_area / (n_neighbor**2)).astype(np.uint8)\n",
    "            # cv2.rectangle(des_img, (left, top), (right, bottom), (0, 0, 255), 2)            \n",
    "                    \n",
    "    def mean_blur_convolution_face_only(self, face, blur_face, radius):\n",
    "        '''\n",
    "        Apply blurring with scipy.convolve2d() to faces only.\n",
    "        '''\n",
    "        n_neighbor = radius*2+1\n",
    "        kernel = np.ones((n_neighbor, n_neighbor))\n",
    "        red = convolve2d(face[:,:,0], kernel, 'same')\n",
    "        green = convolve2d(face[:,:,1], kernel, 'same')\n",
    "        blue = convolve2d(face[:,:,2], kernel, 'same')\n",
    "        convol_area = (np.stack([red, green, blue], axis=2)  / (n_neighbor**2)).astype(np.uint8)\n",
    "\n",
    "        return convol_area\n",
    "                    \n",
    "    def get_face_locations(self, face_detection_model):\n",
    "        '''\n",
    "        Get a list of face_locations on entire video.\n",
    "        '''\n",
    "        des_arr = torch.from_numpy(self.video_array.copy()).to(self.device)\n",
    "        \n",
    "        if face_detection_model != 'mtcnn':\n",
    "            locations = list(map(self.face_detection, des_arr))\n",
    "        else:\n",
    "            locations = list(map(self.face_detection_mtcnn, des_arr))    \n",
    "\n",
    "        return locations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XlXt1jYUbK8_"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue, Lock\n",
    "class video_transformer_multiprocessing(video_transformer_parallel):\n",
    "    '''\n",
    "    This module aims to use multiprocessing to speed up the blurring.\n",
    "    '''\n",
    "    def __init__(self, path, save_path, file_name,N, device='cpu',display=False):\n",
    "        video_transformer_parallel.__init__(self, path, save_path, file_name, \n",
    "                                        device, display)\n",
    "        self.N = N\n",
    "    def mean_blur_one_location(self, locations, i):\n",
    "        '''\n",
    "        Apply the blurring function to only one face.\n",
    "        '''\n",
    "        for location in locations:\n",
    "            top, right, bottom, left = location\n",
    "            face = self.des_arr[i,top:bottom+1, left:right+1, :]\n",
    "            blur_face = np.empty_like(face)\n",
    "            blur_face = self.mean_blur_convolution_face_only(face=face, blur_face=blur_face, radius=self.radius)\n",
    "            self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
    "        return self.des_arr\n",
    "    \n",
    "    def mean_blur_one_frame(self, frame, locations):\n",
    "        '''\n",
    "        Apply the blurring function to all faces within one frame.\n",
    "        '''\n",
    "        for location in locations:\n",
    "            # print(location)\n",
    "            top, right, bottom, left = location\n",
    "            face = frame[top:bottom+1, left:right+1, :]\n",
    "            blur_face = np.empty_like(face)\n",
    "            blur_face = self.mean_blur_convolution_face_only(face=face, blur_face=blur_face, radius=self.radius)\n",
    "            frame[top:bottom+1, left:right+1, :] = blur_face\n",
    "        return frame\n",
    "    def mean_blur_some_frame(self, frames, list_locations, queue, idx):\n",
    "        '''\n",
    "        Apply the blurring effect to all faces within multiple frames.\n",
    "        '''\n",
    "        frames_update = []\n",
    "        for i in range(len(frames)):\n",
    "          frame = frames[i]\n",
    "          locations_=list_locations[i]\n",
    "          frame_update = self.mean_blur_one_frame(frame, locations_)\n",
    "          frames_update.append(frame_update)\n",
    "        queue.put((idx,frames_update))\n",
    "        # return frames_update\n",
    "\n",
    "    def filter_on_video_mult(self, filter_func, radius=10, face_detection_model = 'mtcnn'):\n",
    "        '''\n",
    "        Divide the entire video into several parts, and apply blurring in parallel.\n",
    "        '''\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "        self.radius = radius\n",
    "\n",
    "        frames_portions = list(np.array_split(self.des_arr, self.N))\n",
    "        locations_portions  = list(np.array_split(self.locations, self.N))\n",
    "        q = Queue()\n",
    "        jobs = []\n",
    "        rets = []\n",
    "\n",
    "        lock = Lock()\n",
    "\n",
    "\n",
    "        for i in range(self.N):\n",
    "            p = Process(target=self.mean_blur_some_frame, args=(frames_portions[i],locations_portions[i], q, i))\n",
    "            p.Daemon = True\n",
    "            jobs.append(p)\n",
    "            p.start()\n",
    "            \n",
    "        for p in jobs:\n",
    "            ret = q.get() # will block\n",
    "            rets.append(ret)\n",
    "        for p in jobs:\n",
    "            p.join()\n",
    "            \n",
    "        # sort them by the index to restore order\n",
    "        rets.sort(key=lambda x:x[0])\n",
    "\n",
    "        rets = np.array([ret[1] for ret in rets])\n",
    "        \n",
    "        self.des_arr = np.concatenate(rets).astype(np.uint8)\n",
    "        print(self.des_arr.shape)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrEuxHyeFFoh"
   },
   "source": [
    "# We listed some test cases that are described in the report below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "emd2RSWaA_Id"
   },
   "outputs": [],
   "source": [
    "# CPU Base: use CPU for both face detection (Pytorch) and naive blurring\n",
    "def case1():\n",
    "  case_1 = video_transformer_base(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False)\n",
    "  case_1.main_transformation(\"mtcnn\", case_1.mean_blur)\n",
    "  case_1.write_to_video(\"cpu_base_peds.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nS3Fg7BSIPke"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_base.main_transformation case1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpVu3qfQJ0MI"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 178.407 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: main_transformation at line 54\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    54                                               def main_transformation(self, \n",
    "    55                                                                       face_detection_model, \n",
    "    56                                                                       filter_effect):\n",
    "    57                                                   '''\n",
    "    58                                                   For each frame, do:\n",
    "    59                                                   1. detect the face;\n",
    "    60                                                   2. apply the filter;\n",
    "    61                                                   3. save the processed frame.\n",
    "    62                                                   '''                    \n",
    "    63         1      21666.0  21666.0      0.0          video_capture = cv2.VideoCapture(self.video_path)\n",
    "    64         1          3.0      3.0      0.0          frame_count = 0\n",
    "    65         1          2.0      2.0      0.0          output_frames = []\n",
    "    66       106        565.0      5.3      0.0          while video_capture.isOpened():    \n",
    "    67                                                       # Grab a single frame of video\n",
    "    68       106     631081.0   5953.6      0.4              ret, frame = video_capture.read()\n",
    "    69                                           \n",
    "    70                                                       # Bail out when the video file ends\n",
    "    71       106        365.0      3.4      0.0              if not ret:\n",
    "    72         1       1817.0   1817.0      0.0                  video_capture.release()\n",
    "    73         1          2.0      2.0      0.0                  break\n",
    "    74                                                       \n",
    "    75       105        186.0      1.8      0.0              frame_count += 1\n",
    "    76                                           \n",
    "    77                                                       # detect faces\n",
    "    78       105        154.0      1.5      0.0              if face_detection_model != \"mtcnn\":\n",
    "    79                                                           face_locations = self.face_detection(frame, \n",
    "    80                                                                                                model=face_detection_model)\n",
    "    81                                                       else:\n",
    "    82       105  135018191.0 1285887.5     75.7                  face_locations = self.face_detection_mtcnn(frame)\n",
    "    83                                           \n",
    "    84                                                       # add effect\n",
    "    85       105   42536444.0 405109.0     23.8              after_effect_frame = filter_effect(frame, face_locations)\n",
    "    86                                           \n",
    "    87       105        351.0      3.3      0.0              if self.display and frame_count % 2 == 0:\n",
    "    88                                                          # If faces were found, we will mark it on frame with blue dots\n",
    "    89                                                           for face_location in face_locations:\n",
    "    90                                                               top, right, bottom, left = face_location\n",
    "    91                                                               cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    92                                                           plt.imshow(after_effect_frame)\n",
    "    93                                                           plt.show()\n",
    "    94                                                           clear_output(wait=True)\n",
    "    95                                           \n",
    "    96       105        184.0      1.8      0.0              output_frames.append(after_effect_frame)\n",
    "    97         1          3.0      3.0      0.0          self.num_frames = frame_count\n",
    "    98         1     196095.0 196095.0      0.1          self.des_arr = np.array(output_frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xoIgGeXhFefd"
   },
   "outputs": [],
   "source": [
    "# GPU Base: use GPU for face detection (Pytorch), but CPU for naive blurring\n",
    "def case2():\n",
    "  case_2 = video_transformer_base(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_2.main_transformation(\"mtcnn\", case_2.mean_blur)\n",
    "  case_2.write_to_video(\"gpu_base_peds.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PFv4KOz3KB7p"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_base.main_transformation case2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj-hLcZBKauc"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 80.4681 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: main_transformation at line 54\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    54                                               def main_transformation(self, \n",
    "    55                                                                       face_detection_model, \n",
    "    56                                                                       filter_effect):\n",
    "    57                                                   '''\n",
    "    58                                                   For each frame, do:\n",
    "    59                                                   1. detect the face;\n",
    "    60                                                   2. apply the filter;\n",
    "    61                                                   3. save the processed frame.\n",
    "    62                                                   '''                    \n",
    "    63         1      21063.0  21063.0      0.0          video_capture = cv2.VideoCapture(self.video_path)\n",
    "    64         1          2.0      2.0      0.0          frame_count = 0\n",
    "    65         1          1.0      1.0      0.0          output_frames = []\n",
    "    66       106        583.0      5.5      0.0          while video_capture.isOpened():    \n",
    "    67                                                       # Grab a single frame of video\n",
    "    68       106     786890.0   7423.5      1.0              ret, frame = video_capture.read()\n",
    "    69                                           \n",
    "    70                                                       # Bail out when the video file ends\n",
    "    71       106        380.0      3.6      0.0              if not ret:\n",
    "    72         1        871.0    871.0      0.0                  video_capture.release()\n",
    "    73         1          2.0      2.0      0.0                  break\n",
    "    74                                                       \n",
    "    75       105        179.0      1.7      0.0              frame_count += 1\n",
    "    76                                           \n",
    "    77                                                       # detect faces\n",
    "    78       105        176.0      1.7      0.0              if face_detection_model != \"mtcnn\":\n",
    "    79                                                           face_locations = self.face_detection(frame, \n",
    "    80                                                                                                model=face_detection_model)\n",
    "    81                                                       else:\n",
    "    82       105   36826700.0 350730.5     45.8                  face_locations = self.face_detection_mtcnn(frame)\n",
    "    83                                           \n",
    "    84                                                       # add effect\n",
    "    85       105   42636175.0 406058.8     53.0              after_effect_frame = filter_effect(frame, face_locations)\n",
    "    86                                           \n",
    "    87       105        355.0      3.4      0.0              if self.display and frame_count % 2 == 0:\n",
    "    88                                                          # If faces were found, we will mark it on frame with blue dots\n",
    "    89                                                           for face_location in face_locations:\n",
    "    90                                                               top, right, bottom, left = face_location\n",
    "    91                                                               cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "    92                                                           plt.imshow(after_effect_frame)\n",
    "    93                                                           plt.show()\n",
    "    94                                                           clear_output(wait=True)\n",
    "    95                                           \n",
    "    96       105        183.0      1.7      0.0              output_frames.append(after_effect_frame)\n",
    "    97         1          2.0      2.0      0.0          self.num_frames = frame_count\n",
    "    98         1     194552.0 194552.0      0.2          self.des_arr = np.array(output_frames)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rRpM8oCsun9H"
   },
   "outputs": [],
   "source": [
    "# GPU + Convolution: use GPU for face detection (Pytorch), and CPU for blurring effects using Scipy convolution\n",
    "def case3():\n",
    "  case_3 = video_transformer_parallel(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_3.filter_on_video_face_only(case_3.mean_blur_convolution_face_only)\n",
    "  case_3.write_to_video(\"peds_gpu_parallel_conv.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "l0khZHEvKNO6"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_parallel.filter_on_video_face_only case3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3FLX4Q3LiP5"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 36.3854 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: filter_on_video_face_only at line 241\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   241                                               def filter_on_video_face_only(self, filter_func, radius=10, face_detection_model = 'mtcnn'):\n",
    "   242                                                   '''\n",
    "   243                                                   Filter on the entire video, but the filter function only take in the face regions \n",
    "   244                                                   instead of the entire frame to reduce data size.\n",
    "   245                                                   '''\n",
    "   246         1          6.0      6.0      0.0          k = 1 / (2*radius+1)**2\n",
    "   247         1     132984.0 132984.0      0.4          self.des_arr = self.video_array.copy()\n",
    "   248         1          7.0      7.0      0.0          frame_size = self.video_array.shape[0]\n",
    "   249         1   24130893.0 24130893.0     66.3          self.locations = self.get_face_locations(face_detection_model)\n",
    "   250                                           \n",
    "   251       106        108.0      1.0      0.0          for i in range(frame_size):\n",
    "   252       752       1656.0      2.2      0.0              for location in self.locations[i]:\n",
    "   253       647       3509.0      5.4      0.0                  top, right, bottom, left = location\n",
    "   254       647       1770.0      2.7      0.0                  face = self.des_arr[i, top:bottom+1, left:right+1, :]\n",
    "   255       647       3153.0      4.9      0.0                  blur_face = np.empty_like(face)\n",
    "   256       647   12102849.0  18706.1     33.3                  blur_face = filter_func(face=face, blur_face=blur_face, radius=radius)\n",
    "   257       647       8510.0     13.2      0.0                  self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
    "\n",
    "check\n",
    "39scompleted at 9:25 PM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GCtmDUdU7IaZ"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def img_blur_cuda(img, des_img, k, radius):\n",
    "    '''\n",
    "    numba cuda version of blurring algorithm\n",
    "    '''\n",
    "    i, j = cuda.grid(2)\n",
    "\n",
    "    rows, columns, channel = img.shape\n",
    "    if i >= rows or j >= columns:\n",
    "        return\n",
    "\n",
    "    ra = rows - radius\n",
    "    ca = columns - radius\n",
    "    if i < radius or j < radius or i >= ra or j >= ca:\n",
    "        des_img[i, j, 0] = img[i, j, 0]\n",
    "        des_img[i, j, 1] = img[i, j, 1]\n",
    "        des_img[i, j, 2] = img[i, j, 2]\n",
    "        return\n",
    "\n",
    "    r = 0\n",
    "    g = 0\n",
    "    b = 0\n",
    "    for x in range(-radius, radius + 1):\n",
    "        for y in range(-radius, radius + 1):\n",
    "            i_x = i + x\n",
    "            j_y = j + y\n",
    "            r += img[i_x, j_y, 0] * k\n",
    "            g += img[i_x, j_y, 1] * k\n",
    "            b += img[i_x, j_y, 2] * k\n",
    "    des_img[i, j, 0] = r\n",
    "    des_img[i, j, 1] = g\n",
    "    des_img[i, j, 2] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "m4c2DqtqEi-A"
   },
   "outputs": [],
   "source": [
    "# GPU + CUDA: use GPU for face detection (Pytorch), and CUDA for blurring effects\n",
    "def case4():\n",
    "  case_4 = video_transformer_parallel(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_4.filter_on_video_cuda(img_blur_cuda)\n",
    "  case_4.write_to_video(\"peds_cuda_gpu.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "y8Sgo_UBLYUe"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_parallel.filter_on_video_cuda case4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3ZPPAqaLx-i"
   },
   "source": [
    "```Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 28.8781 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: filter_on_video_cuda at line 204\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   204                                               def filter_on_video_cuda(self, img_blur_cuda, radius=10, face_detection_model = 'mtcnn'):\n",
    "   205                                                   '''\n",
    "   206                                                   Filter on entire video using CUDA for blurring. It specifies block size and controls bounds.\n",
    "   207                                                   '''\n",
    "   208         1          4.0      4.0      0.0          blocksize = (32,32)\n",
    "   209         1          5.0      5.0      0.0          k = 1 / (2*radius+1)**2\n",
    "   210         1     134278.0 134278.0      0.5          self.des_arr = self.video_array.copy()\n",
    "   211         1          7.0      7.0      0.0          frame_size = self.video_array.shape[0]\n",
    "   212         1   25281999.0 25281999.0     87.5          self.locations = self.get_face_locations(face_detection_model)\n",
    "   213         1      18775.0  18775.0      0.1          np.save(\"frame_test.out\", self.des_arr[20])\n",
    "   214         1       3910.0   3910.0      0.0          np.save(\"locations_tests.out\", self.locations[20])\n",
    "   215       106        123.0      1.2      0.0          for i in range(frame_size):\n",
    "   216       752       1745.0      2.3      0.0              for location in self.locations[i]:\n",
    "   217       647       3491.0      5.4      0.0                  top, right, bottom, left = location\n",
    "   218       647      11169.0     17.3      0.0                  face = np.ascontiguousarray(self.des_arr[i, top:bottom+1, left:right+1, :])\n",
    "   219       647       1285.0      2.0      0.0                  gridsize = (face.shape[0]//blocksize[0]+1, face.shape[1]//blocksize[1]+1)\n",
    "   220       647       3653.0      5.6      0.0                  blur_face = np.empty_like(face)\n",
    "   221       647    3406597.0   5265.2     11.8                  img_blur_cuda[gridsize, blocksize](face, blur_face, k, radius)\n",
    "   222       647      11079.0     17.1      0.0                  self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dUQACteGVG8C"
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lXJMC-TzV6WQ"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cv2\n",
    "from scipy.signal import convolve2d\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "ctypedef np.npy_intp SIZE_t\n",
    "\n",
    "def mean_blur_convolution_cython(np.ndarray[np.uint8_t, ndim=3] image, \n",
    "                                 np.ndarray[np.uint8_t, ndim=3] des_img, \n",
    "                                 np.ndarray locations, \n",
    "                                 double radius):\n",
    "    '''\n",
    "    Utilized Scipy convolution to perform blurring effect.\n",
    "    '''\n",
    "    if len(locations) == 0:\n",
    "          # print(\"No faces\")\n",
    "          return\n",
    "    cdef int n_neighbor = np.int32((radius)*2+1)\n",
    "    cdef int height = des_img.shape[0]\n",
    "    cdef int width = des_img.shape[1]\n",
    "    cdef np.ndarray[int, ndim = 2]kernel = np.ones((n_neighbor, n_neighbor),dtype=np.int32)\n",
    "    cdef int t_, b_, l_, r_, bound_top, bound_bottom, bound_left, bound_right\n",
    "\n",
    "    for (top, right, bottom, left) in locations:\n",
    "        t_ = np.int32(max(top+radius,0))\n",
    "        b_ = np.int32(min(bottom-radius, height))\n",
    "        l_ = np.int32(max(left+radius,0))\n",
    "        r_ = np.int32(min(right-radius, width))\n",
    "\n",
    "        bound_top = np.int32(t_-radius)\n",
    "        bound_bottom = np.int32(b_+radius+1)\n",
    "        bound_left = np.int32(l_-radius)\n",
    "        bound_right = np.int32(r_+radius+1)\n",
    "\n",
    "        if t_ >= b_ or l_ >= r_:\n",
    "            continue\n",
    "        \n",
    "        sample_area = image[bound_top:bound_bottom, \n",
    "                            bound_left:bound_right,:]\n",
    "        \n",
    "        # np.save(\"face.out\", sample_area)\n",
    "        red = convolve2d(sample_area[:,:,np.int32(0)], kernel, 'same')\n",
    "        green = convolve2d(sample_area[:,:,np.int32(1)], kernel, 'same')\n",
    "        blue = convolve2d(sample_area[:,:,np.int32(2)], kernel, 'same')\n",
    "\n",
    "        convol_area = np.stack([red, green, blue], axis=2)\n",
    "\n",
    "        des_img[bound_top:bound_bottom, \n",
    "               bound_left:bound_right,:] = (convol_area / (n_neighbor**2)).astype(np.uint8)\n",
    "        cv2.rectangle(des_img, (left, top), (right, bottom), (0, 0, 255), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "QyOGd1Y_WmgD"
   },
   "outputs": [],
   "source": [
    "# GPU + Cythonized Convolution: use GPU for face detection (Pytorch), and use Cython to compile the Scipy Convolution solution\n",
    "def case5():\n",
    "  case_5 = video_transformer_parallel(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_5.filter_on_video(mean_blur_convolution_cython)\n",
    "  case_5.write_to_video(\"peds_gpu_parallel_cython.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4K-HNfKdL9bQ"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_parallel.filter_on_video case5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTqUaC1eNZB4"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 36.4354 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: filter_on_video at line 193\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   193                                               def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
    "   194                                                   '''\n",
    "   195                                                   Apply filter on the video.\n",
    "   196                                                   '''\n",
    "   197         1     133892.0 133892.0      0.4          self.des_arr = self.video_array.copy()\n",
    "   198         1          4.0      4.0      0.0          frame_size = self.video_array.shape[0]\n",
    "   199         1   24316991.0 24316991.0     66.7          self.locations = self.get_face_locations(face_detection_model)\n",
    "   200         1          3.0      3.0      0.0          radius_list = [radius] * frame_size\n",
    "   201                                           \n",
    "   202         1   11984474.0 11984474.0     32.9          list(map(filter_func, self.video_array, self.des_arr, self.locations, radius_list))\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IA9z64yR6y4I"
   },
   "outputs": [],
   "source": [
    "# GPU + Multiprocessing Convolution: use GPU for face detection (Pytorch), and use multiprocessing to blur the images\n",
    "def case6():\n",
    "  case_6 = video_transformer_multiprocessing(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           N=4,\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_6.filter_on_video_mult(case_6.mean_blur_convolution_face_only)\n",
    "  case_6.write_to_video(\"peds_gpu_conv_face_only_mult.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIQjUvMIMVeb",
    "outputId": "468f5a59-278a-4264-8207-657d09a60455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "%lprun -f video_transformer_multiprocessing.filter_on_video_mult case6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qItihrsjM68y"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 39.5816 s\n",
    "File: <ipython-input-5-c6cf6f63823e>\n",
    "Function: filter_on_video_mult at line 47\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    47                                               def filter_on_video_mult(self, filter_func, radius=10, face_detection_model = 'mtcnn'):\n",
    "    48                                                   '''\n",
    "    49                                                   Divide the entire video into several parts, and apply blurring in parallel.\n",
    "    50                                                   '''\n",
    "    51         1     139598.0 139598.0      0.4          self.des_arr = self.video_array.copy()\n",
    "    52         1          7.0      7.0      0.0          frame_size = self.video_array.shape[0]\n",
    "    53         1   24297241.0 24297241.0     61.4          self.locations = self.get_face_locations(face_detection_model)\n",
    "    54         1          4.0      4.0      0.0          self.radius = radius\n",
    "    55                                           \n",
    "    56         1         85.0     85.0      0.0          frames_portions = list(np.array_split(self.des_arr, self.N))\n",
    "    57         1         78.0     78.0      0.0          locations_portions  = list(np.array_split(self.locations, self.N))\n",
    "    58         1        469.0    469.0      0.0          q = Queue()\n",
    "    59         1          1.0      1.0      0.0          jobs = []\n",
    "    60         1          0.0      0.0      0.0          rets = []\n",
    "    61                                           \n",
    "    62         1         82.0     82.0      0.0          lock = Lock()\n",
    "    63                                           \n",
    "    64                                           \n",
    "    65         5         55.0     11.0      0.0          for i in range(self.N):\n",
    "    66         4        756.0    189.0      0.0              p = Process(target=self.mean_blur_some_frame, args=(frames_portions[i],locations_portions[i], q, i))\n",
    "    67         4         24.0      6.0      0.0              p.Daemon = True\n",
    "    68         4         37.0      9.2      0.0              jobs.append(p)\n",
    "    69         4     153934.0  38483.5      0.4              p.start()\n",
    "    70                                                       \n",
    "    71         5         19.0      3.8      0.0          for p in jobs:\n",
    "    72         4   14532106.0 3633026.5     36.7              ret = q.get() # will block\n",
    "    73         4         27.0      6.8      0.0              rets.append(ret)\n",
    "    74         5          8.0      1.6      0.0          for p in jobs:\n",
    "    75         4       7610.0   1902.5      0.0              p.join()\n",
    "    76                                                       \n",
    "    77                                                   # sort them by the index to restore order\n",
    "    78         1         13.0     13.0      0.0          rets.sort(key=lambda x:x[0])\n",
    "    79                                           \n",
    "    80         1         79.0     79.0      0.0          rets = np.array([ret[1] for ret in rets])\n",
    "    81                                                   \n",
    "    82         1     449159.0 449159.0      1.1          self.des_arr = np.concatenate(rets).astype(np.uint8)\n",
    "    83         1        250.0    250.0      0.0          print(self.des_arr.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBYVytQ47E2q"
   },
   "outputs": [],
   "source": [
    "# GPU + CV2 (Benchmark): use GPU for face detection (Pytorch), and use cv2.blur() for blurring \n",
    "def case7():\n",
    "  case_cv2 = video_transformer_parallel(path = path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'peds.mp4',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "  case_cv2.filter_on_video_cv2(cv2.blur)\n",
    "  case_cv2.write_to_video(\"peds_gpu_cv2.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VMcCxdBaSmKv"
   },
   "outputs": [],
   "source": [
    "%lprun -f video_transformer_parallel.filter_on_video_cv2 case7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF3xG3M9NGiT"
   },
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 24.5038 s\n",
    "File: <ipython-input-4-6509e3bc97f5>\n",
    "Function: filter_on_video_cv2 at line 224\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "   224                                               def filter_on_video_cv2(self, cv2_blur, radius=10, face_detection_model = 'mtcnn'):\n",
    "   225                                                   '''\n",
    "   226                                                   Filter on entire video using CV2.blur.\n",
    "   227                                                   '''\n",
    "   228         1          7.0      7.0      0.0          k = 1 / (2*radius+1)**2\n",
    "   229         1     142281.0 142281.0      0.6          self.des_arr = self.video_array.copy()\n",
    "   230         1          5.0      5.0      0.0          frame_size = self.video_array.shape[0]\n",
    "   231         1   24314501.0 24314501.0     99.2          self.locations = self.get_face_locations(face_detection_model)\n",
    "   232                                                   \n",
    "   233       106         62.0      0.6      0.0          for i in range(frame_size):\n",
    "   234       752        715.0      1.0      0.0              for location in self.locations[i]:\n",
    "   235       647       1229.0      1.9      0.0                  top, right, bottom, left = location\n",
    "   236       647       1207.0      1.9      0.0                  face = self.des_arr[i, top:bottom+1, left:right+1, :]\n",
    "   237       647       1559.0      2.4      0.0                  blur_face = np.empty_like(face)\n",
    "   238       647      39785.0     61.5      0.2                  cv2_blur(src=face, dst=blur_face, ksize=(radius,radius))\n",
    "   239       647       2439.0      3.8      0.0                  self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "line_profiler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
