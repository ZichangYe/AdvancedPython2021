{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpdG99uzA_IN"
   },
   "source": [
    "**Purpose:**\n",
    "This notebook should consist of our methods of detecting faces and adding effects on top on them in a video.\n",
    "\n",
    "**Logs:**\n",
    "- May 3, 2021: Write a class to wrap the face detection and mean blur effect.\n",
    "- May 3, 2021: Include a new face detection model MTCNN that can leverages GPU through PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T02:09:08.855105Z",
     "start_time": "2021-05-04T02:09:02.561765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYuvpb2BCLzr",
    "outputId": "7a95063c-a758-4e6d-f13f-28b42b049a44"
   },
   "outputs": [],
   "source": [
    "!pip install face_recognition\n",
    "!pip install facenet_pytorch\n",
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T02:00:16.522405Z",
     "start_time": "2021-05-04T02:00:16.469763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuKTGOu5A_IY",
    "outputId": "d89aeb50-3fb4-4680-c0ae-e2123bcc3dfb"
   },
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cupy as cp\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.028342Z",
     "start_time": "2021-05-04T01:30:25.023451Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWY0mHJSA_Ib",
    "outputId": "cc2674e4-3ef5-4d7e-82e1-1fe8c00fb48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "run_on_colab = True\n",
    "if run_on_colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  path = \"/content/drive/My Drive/AdvancedPython2021\"\n",
    "else:\n",
    "  path = os.getcwd()\n",
    "\n",
    "file = \"girl.gif\"\n",
    "data_path = os.path.join(path, \"data\", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.574502Z",
     "start_time": "2021-05-04T01:30:25.555058Z"
    },
    "id": "QAfO0x-2A_Ib"
   },
   "outputs": [],
   "source": [
    "class video_transformer():\n",
    "    def __init__(self, \n",
    "                 video_path, save_path, file_name, \n",
    "                 device='cpu',\n",
    "                 display=False):\n",
    "        self.video_path = video_path\n",
    "        self.display = display\n",
    "        self.save_path = save_path\n",
    "        self.file_name = file_name\n",
    "        self.num_frames = 0\n",
    "        if device == 'cpu':\n",
    "          self.device = 'cpu'\n",
    "        else:\n",
    "          self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "    # detect the faces in each frame and add effect on it\n",
    "    def main_transformation(self, \n",
    "                            face_detection_model, \n",
    "                            filter_effect):\n",
    "        video_capture = cv2.VideoCapture(self.video_path)\n",
    "        frame_count = 0\n",
    "        while video_capture.isOpened():    \n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "            \n",
    "            # Bail out when the video file ends\n",
    "            if not ret:\n",
    "                video_capture.release()\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "            # detect faces\n",
    "            if face_detection_model != \"mtcnn\":\n",
    "                face_locations = self.face_detection(frame, \n",
    "                                                     model=face_detection_model)\n",
    "            else:\n",
    "                face_locations = self.face_detection_mtcnn(frame)\n",
    "            \n",
    "            # add effect\n",
    "            after_effect_frame = filter_effect(frame, face_locations)\n",
    "    \n",
    "            if self.display and frame_count % 2 == 0:\n",
    "               # If faces were found, we will mark it on frame with blue dots\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                plt.imshow(after_effect_frame)\n",
    "                plt.show()\n",
    "                clear_output(wait=True)\n",
    "            im = Image.fromarray(after_effect_frame)\n",
    "            im.save(os.path.join(self.save_path, f\"{self.file_name}_prcs_{frame_count}.png\"))\n",
    "                \n",
    "        self.num_frames = frame_count\n",
    "        \n",
    "    # returns the face_locations of one particular frame\n",
    "    def face_detection(self, frame, model='svm'):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_frame, model=model)\n",
    "    \n",
    "        return face_locations\n",
    "    \n",
    "    # face detection with mtcnn\n",
    "    def face_detection_mtcnn(self, frame):\n",
    "        mtcnn = MTCNN(keep_all=True, device=self.device)\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "            \n",
    "        return boxes\n",
    "    \n",
    "    def oil_effect(self, frame):\n",
    "        pass\n",
    "    \n",
    "    def negative_effect(self, frame):\n",
    "        pass\n",
    "    \n",
    "    def filter_effect_cython(self, frame):\n",
    "        pass\n",
    "    \n",
    "    # simple mosaic effect\n",
    "    def mean_blur(self, frame, locations, radius=5):\n",
    "        k = 1 / (radius*2+1)**2\n",
    "        des_img = np.copy(frame)\n",
    "        try:\n",
    "            for location in locations:\n",
    "                top, right, bottom, left = location\n",
    "                t_ = top+radius\n",
    "                b_ = bottom-radius\n",
    "                l_ = left+radius\n",
    "                r_ = right-radius\n",
    "                if t_ >= b_ or l_ >= r_:\n",
    "                    continue\n",
    "\n",
    "                for i, j in product(range(t_, b_), range(l_, r_)):\n",
    "                    kernel = frame[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
    "                    sumed = np.sum(kernel, axis = (0,1)) * k\n",
    "                    des_img[i, j] = sumed.astype(np.uint8)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img\n",
    "    \n",
    "    # construct transformed gif\n",
    "    def output(self):\n",
    "        images = []\n",
    "        frames_count = list(range(1,self.num_frames))\n",
    "        \n",
    "        for i in frames_count:\n",
    "            try:\n",
    "                images.append(imageio.imread(\n",
    "                    os.path.join(self.save_path, f\"{self.file_name}_prcs_{i}.png\")))\n",
    "            except:\n",
    "                pass\n",
    "        imageio.mimsave(os.path.join(self.save_path, f\"{self.file_name}_prcs.gif\"), images)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrEuxHyeFFoh"
   },
   "source": [
    "1. CPU\n",
    "\n",
    "First time run 3.745293617248535s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:33.736139Z",
     "start_time": "2021-05-04T01:30:26.258158Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emd2RSWaA_Id",
    "outputId": "62e2fa71-f256-4c97-a27a-0e3cbdc3f985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 3.5048470497131348s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_1 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False)\n",
    "case_1.main_transformation(\"mtcnn\", case_1.mean_blur)\n",
    "case_1.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJYpusd3FVVz"
   },
   "source": [
    "2. GPU\n",
    "\n",
    "First time run: 13.44s due to data transfer. \n",
    "\n",
    "Second time run: 2.72s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFfPc0G8A_Im",
    "outputId": "8c384c30-0c43-449a-ed35-0bbe71fee0dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 2.724152088165283s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_2 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "case_2.main_transformation(\"mtcnn\", case_2.mean_blur)\n",
    "case_2.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoIgGeXhFefd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "video_transformer_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
