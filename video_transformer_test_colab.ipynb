{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "video_transformer_test_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpdG99uzA_IN"
      },
      "source": [
        "**Purpose:**\n",
        "This notebook should consist of our methods of detecting faces and adding effects on top on them in a video.\n",
        "\n",
        "**Logs:**\n",
        "- May 3, 2021: Write a class to wrap the face detection and mean blur effect.\n",
        "- May 3, 2021: Include a new face detection model MTCNN that can leverages GPU through PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T02:09:08.855105Z",
          "start_time": "2021-05-04T02:09:02.561765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYuvpb2BCLzr",
        "outputId": "cb77a246-2d28-4eab-a52d-a53a717ae266"
      },
      "source": [
        "!pip install face_recognition\n",
        "!pip install facenet_pytorch\n",
        "!pip install mmcv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 70kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=bab9691f86d0290ddf7962c237cd3ce1b407e303265604762fba4268a455c48e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
            "Collecting facenet_pytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e8/5ea742737665ba9396a8a2be3d2e2b49a13804b56a7e7bb101e8731ade8f/facenet_pytorch-2.5.2-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.19.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.9.1+cu101)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision->facenet_pytorch) (3.7.4.3)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n",
            "Collecting mmcv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/94/b7c17ba89689684ba2029e6d20ddf82bd4b69dfee9b4007bb3d5c0f06ae6/mmcv-1.3.3.tar.gz (282kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 5.1MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv) (3.13)\n",
            "Collecting yapf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/0d/8814e79eb865eab42d95023b58b650d01dec6f8ea87fc9260978b1bf2167/yapf-0.31.0-py2.py3-none-any.whl (185kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 33.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mmcv\n",
            "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv: filename=mmcv-1.3.3-py2.py3-none-any.whl size=412342 sha256=a5a1123b2859a7834a2a9eca53ee8e217733f8fe049e82007208ed6cccf640d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/71/ce/a3a6154062e788038be2f044160e5dc70bddcb9076202b5d69\n",
            "Successfully built mmcv\n",
            "Installing collected packages: addict, yapf, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-1.3.3 yapf-0.31.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T17:45:34.219545Z",
          "start_time": "2021-05-04T17:45:34.200672Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuKTGOu5A_IY",
        "outputId": "030bc0a4-050e-4523-89f5-114650c4dd66"
      },
      "source": [
        "%pylab inline \n",
        "import face_recognition\n",
        "import cv2\n",
        "import matplotlib.patches as patches\n",
        "from IPython.display import clear_output\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "from itertools import product\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "# import cupy as cp\n",
        "from time import time\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T01:30:25.028342Z",
          "start_time": "2021-05-04T01:30:25.023451Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWY0mHJSA_Ib",
        "outputId": "555a3b33-ae92-445b-d815-bc5d50062d5e"
      },
      "source": [
        "run_on_colab = True\n",
        "if run_on_colab:\n",
        "  from google.colab import drive\n",
        "  \n",
        "  drive.mount('/content/drive')\n",
        "  path = \"/content/drive/My Drive/AdvancedPython2021\"\n",
        "else:\n",
        "  path = os.getcwd()\n",
        "os.chdir(path)\n",
        "from array_mp4_conversion import array_to_mp4, mp4_to_array\n",
        "file = \"girl.gif\"\n",
        "data_path = os.path.join(path, \"data\", file)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T01:30:25.574502Z",
          "start_time": "2021-05-04T01:30:25.555058Z"
        },
        "code_folding": [],
        "id": "QAfO0x-2A_Ib"
      },
      "source": [
        "'''\n",
        "This script contains the codes that we recently developed, and is used to compile a Cython code.\n",
        "\n",
        "Steps:\n",
        "1. Copy this file to a new .pyx file.\n",
        "2. Compile the code by running python3 setup.py build_ext --inplace.\n",
        "3. Then run test_cython.py.\n",
        "\n",
        "'''\n",
        "import torch\n",
        "import os\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import cv2\n",
        "import matplotlib.patches as patches\n",
        "from IPython.display import clear_output\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "from itertools import product\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from time import time\n",
        "from array_mp4_conversion import array_to_mp4, mp4_to_array\n",
        "from numba import jit, prange, cuda\n",
        "from collections import defaultdict\n",
        "from scipy.signal import convolve2d\n",
        "# cimport numpy as np\n",
        "# ctypedef np.uint8_t D_TYPE\n",
        "\n",
        "path = os.getcwd()\n",
        "\n",
        "class video_transformer_base:\n",
        "    '''\n",
        "    This is the base of video_transformer, containing basic information about the video.\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                path, \n",
        "                save_path, \n",
        "                file_name, \n",
        "                device='cpu',\n",
        "                display=False):\n",
        "        \n",
        "        self.video_path = os.path.join(path, \"data\", file_name)\n",
        "        self.video_array, self.fps = mp4_to_array(self.video_path)\n",
        "        self.display = display\n",
        "        self.save_path = save_path\n",
        "        self.file_name = file_name\n",
        "        self.num_frames = 0\n",
        "        if device == 'cpu':\n",
        "            self.device = 'cpu'\n",
        "        else:\n",
        "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    def main_transformation(self, \n",
        "                            face_detection_model, \n",
        "                            filter_effect):\n",
        "        '''\n",
        "        For each frame, do:\n",
        "        1. detect the face;\n",
        "        2. apply the filter;\n",
        "        3. save the processed frame.\n",
        "        '''                    \n",
        "        video_capture = cv2.VideoCapture(self.video_path)\n",
        "        frame_count = 0\n",
        "        output_frames = []\n",
        "        while video_capture.isOpened():    \n",
        "            # Grab a single frame of video\n",
        "            ret, frame = video_capture.read()\n",
        "            # try:\n",
        "            #   frame = torch.from_numpy(frame).to(self.device)\n",
        "            # except:\n",
        "            #   print(ret)\n",
        "\n",
        "            # Bail out when the video file ends\n",
        "            if not ret:\n",
        "                video_capture.release()\n",
        "                break\n",
        "            \n",
        "            frame_count += 1\n",
        "            # print(frame_count)\n",
        "            # print(type(frame))\n",
        "            # detect faces\n",
        "            if face_detection_model != \"mtcnn\":\n",
        "                face_locations = self.face_detection(frame, \n",
        "                                                     model=face_detection_model)\n",
        "            else:\n",
        "                face_locations = self.face_detection_mtcnn(frame)\n",
        "            # print(f\"{len(face_locations)} face(s) detected at frame {frame_count}.\")\n",
        "\n",
        "            # add effect\n",
        "            after_effect_frame = filter_effect(frame, face_locations)\n",
        "\n",
        "            # print(frame_count)\n",
        "            if self.display and frame_count % 2 == 0:\n",
        "               # If faces were found, we will mark it on frame with blue dots\n",
        "                for face_location in face_locations:\n",
        "                    top, right, bottom, left = face_location\n",
        "                    cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
        "                plt.imshow(after_effect_frame)\n",
        "                plt.show()\n",
        "                clear_output(wait=True)\n",
        "            # im = Image.fromarray(after_effect_frame)\n",
        "            # im.save(os.path.join(self.save_path, f\"{self.file_name}_prcs_{frame_count}.png\"))\n",
        "            output_frames.append(after_effect_frame)\n",
        "        self.num_frames = frame_count\n",
        "        self.des_arr = np.array(output_frames)\n",
        "\n",
        "    def face_detection(self, frame):\n",
        "        '''\n",
        "        Face detection with package face_recognition.\n",
        "        Models includes: svm, knn, cnn.\n",
        "        Currently fixed as model='svm' because model ='cnn' is slow.\n",
        "        '''\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        rgb_frame = frame[:, :, ::-1]\n",
        "        face_locations = face_recognition.face_locations(rgb_frame, model='svm')\n",
        "        # print(f\"{len(face_locations)} face(s) detected.\")\n",
        "        \n",
        "        return face_locations\n",
        "    def face_detection_mtcnn(self, frame):\n",
        "        '''\n",
        "        Face detection with package facenet_pytorch.\n",
        "        MTCNN implemented in Pytorch, so also support CUDA.\n",
        "        '''       \n",
        "\n",
        "        mtcnn = MTCNN(keep_all=True, device=self.device)\n",
        "        boxes, _ = mtcnn.detect(frame)\n",
        "        \n",
        "        if boxes is None:\n",
        "            boxes = []\n",
        "            \n",
        "        boxes = np.array([[box[1], box[2], box[3], box[0]] for box in boxes]).astype(np.int)\n",
        "        # print(f\"{len(boxes)} face(s) detected.\")\n",
        "        return boxes\n",
        "    def oil_effect(self, frame):\n",
        "        pass\n",
        "    \n",
        "    def negative_effect(self, frame, locations):\n",
        "        des_img = np.copy(frame)\n",
        "        try:\n",
        "            for location in locations:\n",
        "                x_, y_, w_, h_ = location\n",
        "                t_ = int(y_)\n",
        "                r_ = int(x_+w_)\n",
        "                b_ = int(y_+h_)\n",
        "                l_ = int(x_)\n",
        "\n",
        "                des_img[t_:b_,l_:r_] = 255 - frame[t_:b_,l_:r_]\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        return des_img\n",
        "\n",
        "    def mean_blur(self, frame, locations, radius=5):\n",
        "        '''\n",
        "        Apply simple mosaic effect to specified regions. \n",
        "        '''\n",
        "        k = 1 / (radius*2+1)**2\n",
        "        des_img = np.copy(frame)\n",
        "        height, width, _ = des_img.shape\n",
        "        # try:\n",
        "        for location in locations:\n",
        "            top, right, bottom, left = location\n",
        "            t_ = max(top+radius,0)\n",
        "            b_ = min(bottom-radius, height)\n",
        "            l_ = max(left+radius,0)\n",
        "            r_ = min(right-radius, width)\n",
        "            if t_ >= b_ or l_ >= r_:\n",
        "                continue\n",
        "\n",
        "            for i, j in product(range(t_, b_), range(l_, r_)):\n",
        "                kernel = frame[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
        "                sumed = np.sum(kernel, axis = (0,1)) * k\n",
        "                des_img[i, j] = sumed.astype(np.uint8)\n",
        "        # except:\n",
        "        #     pass\n",
        "        \n",
        "        return des_img    \n",
        "    \n",
        "    # construct transformed gif\n",
        "    def output(self):\n",
        "        images = []\n",
        "        frames_count = list(range(1,self.num_frames))\n",
        "        \n",
        "        for i in frames_count:\n",
        "            try:\n",
        "                images.append(imageio.imread(\n",
        "                    os.path.join(self.save_path, f\"{self.file_name}_prcs_{i}.png\")))\n",
        "            except:\n",
        "                pass\n",
        "        imageio.mimsave(os.path.join(self.save_path, f\"{self.file_name}_prcs.gif\"), images)\n",
        "    \n",
        "    def write_to_video(self, output_filename):\n",
        "        '''\n",
        "        Write out the video with filter to mp4.\n",
        "        '''\n",
        "        array_to_mp4(output_filename, self.des_arr, self.fps)\n",
        "\n",
        "class video_transformer_parallel(video_transformer_base):\n",
        "    '''\n",
        "    This version views the video as an array for easier parallelization.\n",
        "    '''\n",
        "    def __init__(self, path, save_path, file_name, device='cpu',display=False):\n",
        "        video_transformer_base.__init__(self, path, save_path, file_name, \n",
        "                                        device, display)\n",
        "        \n",
        "        self.locations = None\n",
        "        self.des_arr = None\n",
        "\n",
        "        torch.from_numpy(self.video_array).to(self.device)\n",
        "        \n",
        "    @cuda.jit \n",
        "    def img_blur_cuda(self, img, des_img, k, radius):\n",
        "        '''\n",
        "        numba cuda version of blurring algorithm\n",
        "        '''\n",
        "        i, j = cuda.grid(2)\n",
        "\n",
        "        rows, columns, channel = img.shape\n",
        "        if i >= rows or j >= columns:\n",
        "            return\n",
        "\n",
        "        ra = rows - radius\n",
        "        ca = columns - radius\n",
        "        if i < radius or j < radius or i >= ra or j >= ca:\n",
        "            des_img[i, j, 0] = img[i, j, 0]\n",
        "            des_img[i, j, 1] = img[i, j, 1]\n",
        "            des_img[i, j, 2] = img[i, j, 2]\n",
        "            return\n",
        "\n",
        "        r = 0\n",
        "        g = 0\n",
        "        b = 0\n",
        "        for x in range(-radius, radius+1):\n",
        "            for y in range(-radius, radius+1):\n",
        "                i_x = i + x\n",
        "                j_y = j + y\n",
        "                r += img[i_x, j_y, 0] * k\n",
        "                g += img[i_x, j_y, 1] * k\n",
        "                b += img[i_x, j_y, 2] * k\n",
        "        des_img[i, j, 0] = r\n",
        "        des_img[i, j, 1] = g\n",
        "        des_img[i, j, 2] = b\n",
        "        \n",
        "        \n",
        "    def filter_on_video_cuda(self, radius=10, face_detection_model = 'mtcnn'):\n",
        "        blocksize = (32,32)\n",
        "        k = 1 / (2*radius+1)**2\n",
        "        self.des_arr = self.video_array.copy()\n",
        "        frame_size = self.video_array.shape[0]\n",
        "        self.locations = self.get_face_locations(face_detection_model)\n",
        "        for i in range(frame_size):\n",
        "            for location in self.locations[i]:\n",
        "                top, right, bottom, left = location\n",
        "                face = np.ascontiguousarray(self.des_arr[i, top:bottom+1, left:right+1, :])\n",
        "                gridsize = (face.shape[0]//blocksize[0]+1, face.shape[1]//blocksize[1]+1)\n",
        "                blur_face = np.empty_like(face)\n",
        "                self.img_blur_cuda[gridsize, blocksize](face, blur_face, k, radius)\n",
        "                self.des_arr[i, top:bottom+1, left:right+1, :] = blur_face\n",
        "    \n",
        "    \n",
        "    # @jit(nopython=False, parallel=True)\n",
        "    def mean_blur_git(self, image, des_img, locations, radius):\n",
        "        '''\n",
        "        mean_blur function with a source and destination image, the logic remains the same.\n",
        "        '''\n",
        "        # radius has to be even\n",
        "        if len(locations) == 0:\n",
        "            print(\"No faces\")\n",
        "            return\n",
        "        # print(len(locations))\n",
        "        k = 1 / (radius*2+1)**2\n",
        "        height, width, _ = des_img.shape\n",
        "        for (top, right, bottom, left) in locations:\n",
        "            t_ = max(top+radius,0)\n",
        "            b_ = min(bottom-radius, height)\n",
        "            l_ = max(left+radius,0)\n",
        "            r_ = min(right-radius, width)\n",
        "\n",
        "            if t_ >= b_ or l_ >= r_:\n",
        "                continue\n",
        "          \n",
        "            for i, j in product(range(t_, b_), range(l_, r_)):\n",
        "                summed = np.sum(image[i-radius:i+radius+1, j-radius:j+radius+1, :], axis = (0,1), dtype=np.uint32)\n",
        "                # print(summed)\n",
        "                # sumed = np.sum(np.sum(kernel, axis= 0, dtype=np.uint32), axis=0)\n",
        "                # sumed = np.sum(kernel, axis=(0,1), dtype=np.uint32)\n",
        "                des_img[i, j, :] = (summed * k).astype(np.uint8)\n",
        "            \n",
        "            cv2.rectangle(des_img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "    \n",
        "    def mean_blur_convolution(self, image, des_img, locations, radius):\n",
        "        '''\n",
        "        Utilized Scipy convolution to perform blurring effect.\n",
        "        '''\n",
        "        if len(locations) == 0:\n",
        "              print(\"No faces\")\n",
        "              return\n",
        "          # print(len(locations))\n",
        "        n_neighbor = radius*2+1\n",
        "        height, width, _ = des_img.shape\n",
        "        for (top, right, bottom, left) in locations:\n",
        "            t_ = max(top+radius,0)\n",
        "            b_ = min(bottom-radius, height)\n",
        "            l_ = max(left+radius,0)\n",
        "            r_ = min(right-radius, width)\n",
        "\n",
        "            if t_ >= b_ or l_ >= r_:\n",
        "                continue\n",
        "            \n",
        "            sample_area = image[t_-radius:b_+radius+1, l_-radius:r_+radius+1,:].astype(np.uint8)\n",
        "            \n",
        "            kernel = np.ones((n_neighbor, n_neighbor))\n",
        "\n",
        "            # np.save(\"face.out\", sample_area)\n",
        "            red = convolve2d(sample_area[:,:,0], kernel, 'same')\n",
        "            green = convolve2d(sample_area[:,:,1], kernel, 'same')\n",
        "            blue = convolve2d(sample_area[:,:,2], kernel, 'same')\n",
        "\n",
        "            convol_area = np.stack([red, green, blue], axis=2)\n",
        "\n",
        "            des_img[t_-radius:b_+radius+1, l_-radius:r_+radius+1,:] = (convol_area / (n_neighbor**2)).astype(np.uint8)\n",
        "            cv2.rectangle(des_img, (left, top), (right, bottom), (0, 0, 255), 2)            \n",
        "                    \n",
        "                    \n",
        "    def get_face_locations(self, face_detection_model):\n",
        "        '''\n",
        "        get face_locations on entire video as an array.\n",
        "        '''\n",
        "        des_arr = torch.from_numpy(self.video_array.copy()).to(self.device)\n",
        "        \n",
        "        if face_detection_model != 'mtcnn':\n",
        "            locations = list(map(self.face_detection, des_arr))\n",
        "        else:\n",
        "            locations = list(map(self.face_detection_mtcnn, des_arr))    \n",
        "\n",
        "        return locations\n",
        "    \n",
        "    \n",
        "    @jit(nopython=False, parallel=True)\n",
        "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
        "        '''\n",
        "        Produce filter on the video.\n",
        "        '''\n",
        "        self.des_arr = self.video_array.copy()\n",
        "        frame_size = self.video_array.shape[0]\n",
        "        self.locations = self.get_face_locations(face_detection_model)\n",
        "        radius_list = [radius] * frame_size\n",
        "\n",
        "        list(map(filter_func, self.video_array, self.des_arr, self.locations, radius_list))\n",
        "#         for i in prange(frame_size):\n",
        "#             filter_func(self.video_array[i], self.des_arr[i], self.locations[i], radius)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEuxHyeFFoh"
      },
      "source": [
        "**1. Base**\n",
        "\n",
        "peds_shorts.mp4 w/ Colab CPU: \n",
        "- 1st: 65.86514019966125s.\n",
        "\n",
        "Peds_short.mp4 w/ Colab GPU\n",
        "- 1st: 32.44067120552063s.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T01:30:33.736139Z",
          "start_time": "2021-05-04T01:30:26.258158Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emd2RSWaA_Id",
        "outputId": "0021f464-d6c4-4f1d-9ea3-c1b0ce5a014d"
      },
      "source": [
        "ts = time()\n",
        "case_1 = video_transformer_base(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds.mp4',\n",
        "                           display=False)\n",
        "case_1.main_transformation(\"mtcnn\", case_1.mean_blur)\n",
        "case_1.write_to_video()\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time used 162.5575568675995s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJYpusd3FVVz"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoIgGeXhFefd",
        "outputId": "14701310-71e4-49fb-ef8d-6c5933a651dc"
      },
      "source": [
        "ts = time()\n",
        "case_2 = video_transformer_base(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_2.main_transformation(\"mtcnn\", case_2.mean_blur)\n",
        "case_2.write_to_video()\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time used 55.120919942855835s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiW8_XDGDURx"
      },
      "source": [
        "ts = time()\n",
        "case_3 = video_transformer_base(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'hamilton_clip.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_3.main_transformation(\"mtcnn\", case_3.negative_effect)\n",
        "case_3.output()\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6cLO-1xEi-A"
      },
      "source": [
        "**2. Parallel**\n",
        "\n",
        "Speeds of Peds_short:\n",
        "  - w/ GPU: 33s\n",
        "  - w/ CPU: 155s\n",
        "  - w/ GPU + convolution blurring: 17s\n",
        "\n",
        "Issues:\n",
        "  - Less faced detected:\n",
        "    - Solved by activating iterator ```list(map())```.\n",
        "  - ```array_detection()```\n",
        "    - RAM not enough\n",
        "    - Slower\n",
        "  - ```@jit mean_blur_jit()```\n",
        "    - showing only one location at one time.\n",
        "    - Add the if ```len()==0``` return statement, still doesn'work.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T20:53:37.786185Z",
          "start_time": "2021-05-04T20:53:37.683548Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11zzHv0LEi-A",
        "outputId": "155e51ba-8506-4bca-b1cc-afcf7762e721"
      },
      "source": [
        "ts = time()\n",
        "case_4 = video_transformer_parallel(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds_short.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_4.filter_on_video(case_4.mean_blur_git)\n",
        "case_4.write_to_video(\"peds_short_gpu_parallel.mp4\")\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-8-fc5b7855901e>:348: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"filter_on_video\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-8-fc5b7855901e> (353)\n",
            "\n",
            "File \"<ipython-input-8-fc5b7855901e>\", line 353:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "        <source elided>\n",
            "        '''\n",
            "        self.des_arr = self.video_array.copy()\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"filter_on_video\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-8-fc5b7855901e>\", line 349:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-8-fc5b7855901e>\", line 349:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No faces\n",
            "Time used 38.76287817955017s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRpM8oCsun9H",
        "outputId": "2c388026-4004-43cd-a922-9fcf227f6a14"
      },
      "source": [
        "ts = time()\n",
        "case_5 = video_transformer_parallel(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds_short.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_5.filter_on_video(case_5.mean_blur_convolution)\n",
        "case_5.write_to_video(\"peds_short_gpu_parallel_conv.mp4\")\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-11-fa9dcc3d33a0>:349: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"filter_on_video\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-11-fa9dcc3d33a0> (354)\n",
            "\n",
            "File \"<ipython-input-11-fa9dcc3d33a0>\", line 354:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "        <source elided>\n",
            "        '''\n",
            "        self.des_arr = self.video_array.copy()\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"filter_on_video\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-11-fa9dcc3d33a0>\", line 350:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-11-fa9dcc3d33a0>\", line 350:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No faces\n",
            "Time used 21.05466604232788s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uJFI33nFuw_P",
        "outputId": "9f9584ca-7772-4ecd-a2eb-3c1693a172d9"
      },
      "source": [
        "ts = time()\n",
        "case_6 = video_transformer_parallel(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds_short.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_6.filter_on_video_cuda()\n",
        "case_6.write_to_video(\"peds_short_gpu_parallel_cuda.mp4\")\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-63fd36ad14ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                            \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                            device='gpu')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcase_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_on_video_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcase_6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_to_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"peds_short_gpu_parallel_cuda.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time used {time() - ts}s.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-fa9dcc3d33a0>\u001b[0m in \u001b[0;36mfilter_on_video_cuda\u001b[0;34m(self, radius, face_detection_model)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mgridsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mblocksize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mblur_face\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_blur_cuda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgridsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblur_face\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdes_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblur_face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0;32m--> 770\u001b[0;31m                                     self.stream, self.sharedmem)\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    859\u001b[0m         argtypes = tuple(\n\u001b[1;32m    860\u001b[0m             [self.typingctx.resolve_argument_type(a) for a in args])\n\u001b[0;32m--> 861\u001b[0;31m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    930\u001b[0m             kernel = compile_kernel(self.py_func, argtypes,\n\u001b[1;32m    931\u001b[0m                                     \u001b[0mlink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m                                     **self.targetoptions)\n\u001b[0m\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_kernel\u001b[0;34m(pyfunc, args, link, debug, inline, fastmath, extensions, max_registers, opt)\u001b[0m\n\u001b[1;32m     55\u001b[0m def compile_kernel(pyfunc, args, link, debug=False, inline=False,\n\u001b[1;32m     56\u001b[0m                    fastmath=False, extensions=[], max_registers=None, opt=True):\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllvm_func_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     lib, kernel = cres.target_context.prepare_cuda_kernel(cres.library, fname,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_cuda\u001b[0;34m(pyfunc, return_type, args, debug, inline)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                   \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                                   \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                   locals={})\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mlibrary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    625\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    626\u001b[0m                               args, return_type, flags, locals)\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfail_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCompilerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All available pipelines exhausted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mpatched_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_patch_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdependency_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legacy pass in use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_initialization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpass_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfinalize_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_finalizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mmangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmangled\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 msg = (\"CompilerPass implementations should return True/False. \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numba/core/untyped_passes.py\u001b[0m in \u001b[0;36mrun_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    105\u001b[0m             raise TypeError(\"Signature mismatch: %d argument types given, \"\n\u001b[1;32m    106\u001b[0m                             \u001b[0;34m\"but function takes %d arguments\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                             % (len(state['args']), state['nargs']))\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Failed in nopython mode pipeline (step: fix up args)\nSignature mismatch: 4 argument types given, but function takes 5 arguments"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-04T20:56:03.745231Z",
          "start_time": "2021-05-04T20:56:02.915598Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7dfjLAEi-A",
        "outputId": "a4ef9942-1556-470e-b990-09bd7118b579"
      },
      "source": [
        "ts = time()\n",
        "case_5 = video_transformer_parallel(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds.mp4',\n",
        "                           display=False,\n",
        "                           device='cpu')\n",
        "case_5.filter_on_video(case_5.mean_blur)\n",
        "case_5.write_to_video(output_filename = case_5.file_name+\"_cpu_parallel.mp4\")\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-71-652cb470f072>:256: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"filter_on_video\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-71-652cb470f072> (261)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 261:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        '''\n",
            "        self.des_arr = self.video_array.copy()\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "<ipython-input-71-652cb470f072>:256: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"filter_on_video\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 264:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        self.locations = self.get_face_locations(face_detection_model)\n",
            "        for i in prange(frame_size):\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"filter_on_video\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 261:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        '''\n",
            "        self.des_arr = self.video_array.copy()\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 261:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        '''\n",
            "        self.des_arr = self.video_array.copy()\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "<ipython-input-71-652cb470f072>:243: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"get_face_locations\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-71-652cb470f072> (248)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 248:\n",
            "    def get_face_locations(self, face_detection_model):\n",
            "        <source elided>\n",
            "        '''\n",
            "        des_arr = torch.from_numpy(self.video_array.copy()).to(self.device)\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"get_face_locations\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 244:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def get_face_locations(self, face_detection_model):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 244:\n",
            "    @jit(nopython=False, parallel=True)\n",
            "    def get_face_locations(self, face_detection_model):\n",
            "    ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "<ipython-input-71-652cb470f072>:256: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"filter_on_video\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-71-652cb470f072> (264)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 264:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        self.locations = self.get_face_locations(face_detection_model)\n",
            "        for i in prange(frame_size):\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, parallel=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"filter_on_video\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 264:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        self.locations = self.get_face_locations(face_detection_model)\n",
            "        for i in prange(frame_size):\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 264:\n",
            "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 15):\n",
            "        <source elided>\n",
            "        self.locations = self.get_face_locations(face_detection_model)\n",
            "        for i in prange(frame_size):\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "<ipython-input-71-652cb470f072>:219: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"mean_blur\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-71-652cb470f072> (225)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 225:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        # radius has to be even\n",
            "        if len(locations) == 0:\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, fastmath=True)\n",
            "<ipython-input-71-652cb470f072>:219: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"mean_blur\" failed type inference due to: cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 229:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        height, width, _ = des_img.shape\n",
            "        for location in locations:\n",
            "        ^\n",
            "\n",
            "  @jit(nopython=False, fastmath=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"mean_blur\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 225:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        # radius has to be even\n",
            "        if len(locations) == 0:\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 225:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        # radius has to be even\n",
            "        if len(locations) == 0:\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "<ipython-input-71-652cb470f072>:219: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"mean_blur\" failed type inference due to: Cannot unify array(uint32, 2d, C) and array(uint64, 1d, C) for 'sumed', defined at <ipython-input-71-652cb470f072> (240)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 240:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "                    kernel = image[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
            "                    sumed = np.sum(kernel, axis= 0, dtype=np.uint32)\n",
            "                    ^\n",
            "\n",
            "During: typing of assignment at <ipython-input-71-652cb470f072> (241)\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 241:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "                    sumed = np.sum(kernel, axis= 0, dtype=np.uint32)\n",
            "                    sumed = np.sum(sumed, axis=0)\n",
            "                    ^\n",
            "\n",
            "  @jit(nopython=False, fastmath=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"mean_blur\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 229:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        height, width, _ = des_img.shape\n",
            "        for location in locations:\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n",
            "/usr/local/lib/python3.7/dist-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-71-652cb470f072>\", line 229:\n",
            "    def mean_blur(self, image, des_img, locations, radius):\n",
            "        <source elided>\n",
            "        height, width, _ = des_img.shape\n",
            "        for location in locations:\n",
            "        ^\n",
            "\n",
            "  state.func_ir.loc))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time used 155.43925189971924s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAxbwUERh6Hn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-05T22:40:53.009528Z",
          "start_time": "2021-05-05T22:40:51.974855Z"
        },
        "id": "wuIWcdaPjqJx"
      },
      "source": [
        "ts = time()\n",
        "case_4 = video_transformer_parallel(path = path,\n",
        "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
        "                           file_name = 'peds_short.mp4',\n",
        "                           display=False,\n",
        "                           device='gpu')\n",
        "case_4.filter_on_video(case_4.mean_blur_convolution)\n",
        "case_4.write_to_video(\"peds_short_gpu_parallel.mp4\")\n",
        "print(f\"Time used {time() - ts}s.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku_7ET3ok6-i"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4c2DqtqEi-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmHXZraBZ2M6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IMwsb1iZ7b4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}