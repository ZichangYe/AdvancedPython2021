{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpdG99uzA_IN"
   },
   "source": [
    "**Purpose:**\n",
    "This notebook should consist of our methods of detecting faces and adding effects on top on them in a video.\n",
    "\n",
    "**Logs:**\n",
    "- May 3, 2021: Write a class to wrap the face detection and mean blur effect.\n",
    "- May 3, 2021: Include a new face detection model MTCNN that can leverages GPU through PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T02:09:08.855105Z",
     "start_time": "2021-05-04T02:09:02.561765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYuvpb2BCLzr",
    "outputId": "23bea0fc-3ecc-4c3e-8c7d-67b244f296a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
      "Requirement already satisfied: facenet_pytorch in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.9.1+cu101)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.8.1+cu101)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision->facenet_pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: mmcv in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv) (1.19.5)\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv) (0.31.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv) (3.13)\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition\n",
    "!pip install facenet_pytorch\n",
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T17:45:34.219545Z",
     "start_time": "2021-05-04T17:45:34.200672Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuKTGOu5A_IY",
    "outputId": "31adb474-ce7a-40a2-b28f-ca5e3ca7a3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yezichang/opt/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['product', 'plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import cupy as cp\n",
    "from time import time\n",
    "from array_mp4_conversion import array_to_mp4, mp4_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.028342Z",
     "start_time": "2021-05-04T01:30:25.023451Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWY0mHJSA_Ib",
    "outputId": "9d6014b8-e9b2-4bfb-bf82-0305b8648d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "run_on_colab = True\n",
    "if run_on_colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  path = \"/content/drive/My Drive/3001/proj/AdvancedPython2021\"\n",
    "else:\n",
    "  path = os.getcwd()\n",
    "\n",
    "file = \"girl.gif\"\n",
    "data_path = os.path.join(path, \"data\", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.574502Z",
     "start_time": "2021-05-04T01:30:25.555058Z"
    },
    "id": "QAfO0x-2A_Ib"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This script contains the codes that we recently developed, and is used to compile a Cython code.\n",
    "\n",
    "Steps:\n",
    "1. Copy this file to a new .pyx file.\n",
    "2. Compile the code by running python3 setup.py build_ext --inplace.\n",
    "3. Then run test_cython.py.\n",
    "\n",
    "'''\n",
    "import torch\n",
    "import os\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from array_mp4_conversion import array_to_mp4, mp4_to_array\n",
    "from numba import jit, prange\n",
    "from collections import defaultdict\n",
    "cimport numpy as np\n",
    "ctypedef np.uint8_t D_TYPE\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "class video_transformer_base:\n",
    "    '''\n",
    "    This is the base of video_transformer, containing basic information about the video.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                path, \n",
    "                save_path, \n",
    "                file_name, \n",
    "                device='cpu',\n",
    "                display=False):\n",
    "        \n",
    "        self.video_path = os.path.join(path, \"data\", file_name)\n",
    "        self.display = display\n",
    "        self.save_path = save_path\n",
    "        self.file_name = file_name\n",
    "        self.num_frames = 0\n",
    "        if device == 'cpu':\n",
    "          self.device = 'cpu'\n",
    "        else:\n",
    "          self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    def main_transformation(self, \n",
    "                            face_detection_model, \n",
    "                            filter_effect):\n",
    "        '''\n",
    "        For each frame, do:\n",
    "        1. detect the face;\n",
    "        2. apply the filter;\n",
    "        3. save the processed frame.\n",
    "        '''                    \n",
    "        video_capture = cv2.VideoCapture(self.video_path)\n",
    "        frame_count = 0\n",
    "        while video_capture.isOpened():    \n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "            \n",
    "            # Bail out when the video file ends\n",
    "            if not ret:\n",
    "                video_capture.release()\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            # print(frame_count)\n",
    "            # print(type(frame))\n",
    "            # detect faces\n",
    "            if face_detection_model != \"mtcnn\":\n",
    "                face_locations = self.face_detection(frame, \n",
    "                                                     model=face_detection_model)\n",
    "            else:\n",
    "                face_locations = self.face_detection_mtcnn(frame)\n",
    "            # print(f\"{len(face_locations)} face(s) detected at frame {frame_count}.\")\n",
    "\n",
    "            # add effect\n",
    "            after_effect_frame = filter_effect(frame, face_locations)\n",
    "\n",
    "            # print(frame_count)\n",
    "            if self.display and frame_count % 2 == 0:\n",
    "               # If faces were found, we will mark it on frame with blue dots\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                plt.imshow(after_effect_frame)\n",
    "                plt.show()\n",
    "                clear_output(wait=True)\n",
    "            im = Image.fromarray(after_effect_frame)\n",
    "            im.save(os.path.join(self.save_path, f\"{self.file_name}_prcs_{frame_count}.png\"))\n",
    "                \n",
    "        self.num_frames = frame_count\n",
    "        \n",
    "    def face_detection(self, frame):\n",
    "        '''\n",
    "        Face detection with package face_recognition.\n",
    "        Models includes: svm, knn, cnn.\n",
    "        Currently fixed as model='svm' because model ='cnn' is slow.\n",
    "        '''\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_frame, model='svm')\n",
    "        # print(f\"{len(face_locations)} face(s) detected.\")\n",
    "        \n",
    "        return face_locations\n",
    "    def face_detection_mtcnn(self, frame):\n",
    "        '''\n",
    "        Face detection with package facenet_pytorch.\n",
    "        MTCNN implemented in Pytorch, so also support CUDA.\n",
    "        '''       \n",
    "\n",
    "        mtcnn = MTCNN(keep_all=True, device=self.device)\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "            \n",
    "        boxes = np.array([[box[1], box[2], box[3], box[0]] for box in boxes]).astype(np.int)\n",
    "        # print(f\"{len(boxes)} face(s) detected.\")\n",
    "        return boxes\n",
    "    def oil_effect(self, frame):\n",
    "        pass\n",
    "    \n",
    "    def negative_effect(self, frame, locations):\n",
    "        des_img = np.copy(frame)\n",
    "        try:\n",
    "            for location in locations:\n",
    "                x_, y_, w_, h_ = location\n",
    "                t_ = int(y_)\n",
    "                r_ = int(x_+w_)\n",
    "                b_ = int(y_+h_)\n",
    "                l_ = int(x_)\n",
    "\n",
    "                des_img[t_:b_,l_:r_] = 255 - frame[t_:b_,l_:r_]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img\n",
    "\n",
    "    def mean_blur(self, frame, locations, radius=5):\n",
    "        '''\n",
    "        Apply simple mosaic effect to specified regions. \n",
    "        '''\n",
    "        k = 1 / (radius*2+1)**2\n",
    "        des_img = np.copy(frame)\n",
    "        height, width, _ = des_img.shape\n",
    "        try:\n",
    "            for location in locations:\n",
    "                top, right, bottom, left = location\n",
    "                t_ = max(top+radius,0)\n",
    "                b_ = min(bottom-radius, height)\n",
    "                l_ = max(left+radius,0)\n",
    "                r_ = min(right-radius, width)\n",
    "                if t_ >= b_ or l_ >= r_:\n",
    "                    continue\n",
    "\n",
    "                for i, j in product(range(t_, b_), range(l_, r_)):\n",
    "                    kernel = frame[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
    "                    sumed = np.sum(kernel, axis = (0,1)) * k\n",
    "                    des_img[i, j] = sumed.astype(np.uint8)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img    \n",
    "\n",
    "\n",
    "class video_transformer_parallel(video_transformer_base):\n",
    "    '''\n",
    "    This version views the video as an array for easier parallelization.\n",
    "    '''\n",
    "    def __init__(self, path, save_path, file_name, device='cpu',display=False):\n",
    "        video_transformer_base.__init__(self, path, save_path, file_name, device, display)\n",
    "        self.video_array, self.fps = mp4_to_array(self.video_path)\n",
    "        self.locations = None\n",
    "        self.des_arr = None\n",
    "    \n",
    "\n",
    "    def mean_blur(self, image, des_img, locations, radius):\n",
    "        '''\n",
    "        mean_blur function with a source and destination image, the logic remains the same.\n",
    "        '''\n",
    "        # radius has to be even\n",
    "        if len(locations) == 0:\n",
    "            return\n",
    "        k = 1 / (radius*2+1)**2\n",
    "        height, width, _ = des_img.shape\n",
    "        for location in locations:\n",
    "            top, right, bottom, left = location\n",
    "            t_ = max(top+radius,0)\n",
    "            b_ = min(bottom-radius, height)\n",
    "            l_ = max(left+radius,0)\n",
    "            r_ = min(right-radius, width)\n",
    "            if t_ >= b_ or l_ >= r_:\n",
    "                continue\n",
    "            for i in range(t_, b_):\n",
    "                for j in range(l_, r_):\n",
    "                    kernel = image[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
    "                    sumed = np.sum(kernel, axis= 0, dtype=np.uint32)\n",
    "                    sumed = np.sum(sumed, axis=0)\n",
    "                    des_img[i, j, :] = (sumed * k).astype(np.uint8)\n",
    "\n",
    "    def get_face_locations(self, face_detection_model):\n",
    "        '''\n",
    "        get face_locations on entire video as an array.\n",
    "        '''\n",
    "        des_arr = self.video_array.copy()\n",
    "        \n",
    "        if face_detection_model != 'mtcnn':\n",
    "            locations = list(map(self.face_detection, des_arr))\n",
    "        else:\n",
    "            locations = list(map(self.face_detection_mtcnn, des_arr))    \n",
    "\n",
    "        return locations\n",
    "\n",
    "    def filter_on_video(self, filter_func, face_detection_model = 'mtcnn', radius = 10):\n",
    "        '''\n",
    "        Produce filter on the video.\n",
    "        '''\n",
    "        self.des_arr = self.video_array.copy()\n",
    "        frame_size = self.video_array.shape[0]\n",
    "        self.locations = self.get_face_locations(face_detection_model)\n",
    "        for i in prange(frame_size):\n",
    "            filter_func(self.video_array[i], self.des_arr[i], self.locations[i], radius)\n",
    "\n",
    "        \n",
    "    def write_to_video(self):\n",
    "        '''\n",
    "        Write out the video with filter to mp4.\n",
    "        '''\n",
    "        array_to_mp4(self.file_name, self.des_arr, self.fps)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrEuxHyeFFoh"
   },
   "source": [
    "1. CPU\n",
    "\n",
    "First time run 3.745293617248535s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:33.736139Z",
     "start_time": "2021-05-04T01:30:26.258158Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emd2RSWaA_Id",
    "outputId": "c7a6b5c5-b1c0-456a-b0c6-c217dac3639d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 3.2356338500976562s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_1 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False)\n",
    "case_1.main_transformation(\"mtcnn\", case_1.mean_blur)\n",
    "case_1.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJYpusd3FVVz"
   },
   "source": [
    "2. GPU\n",
    "\n",
    "First time run: 13.44s due to data transfer. \n",
    "\n",
    "Second time run: 2.72s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoIgGeXhFefd",
    "outputId": "143b0a08-93f7-4f79-f29f-7b0b39cb3456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 2.5132715702056885s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_2 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "case_2.main_transformation(\"mtcnn\", case_2.mean_blur)\n",
    "case_2.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiW8_XDGDURx",
    "outputId": "093860e4-1027-479f-a7af-00d3ca0efb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 2.4300358295440674s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_3 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "case_3.main_transformation(\"mtcnn\", case_3.negative_effect)\n",
    "case_3.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cython*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T20:53:37.786185Z",
     "start_time": "2021-05-04T20:53:37.683548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T20:56:03.745231Z",
     "start_time": "2021-05-04T20:56:02.915598Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "video_transformer_test_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
