{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpdG99uzA_IN"
   },
   "source": [
    "**Purpose:**\n",
    "This notebook should consist of our methods of detecting faces and adding effects on top on them in a video.\n",
    "\n",
    "**Logs:**\n",
    "- May 3, 2021: Write a class to wrap the face detection and mean blur effect.\n",
    "- May 3, 2021: Include a new face detection model MTCNN that can leverages GPU through PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T02:09:08.855105Z",
     "start_time": "2021-05-04T02:09:02.561765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYuvpb2BCLzr",
    "outputId": "23bea0fc-3ecc-4c3e-8c7d-67b244f296a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
      "Requirement already satisfied: facenet_pytorch in /usr/local/lib/python3.7/dist-packages (2.5.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.9.1+cu101)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.8.1+cu101)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision->facenet_pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: mmcv in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv) (1.19.5)\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv) (0.31.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv) (3.13)\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition\n",
    "!pip install facenet_pytorch\n",
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T02:00:16.522405Z",
     "start_time": "2021-05-04T02:00:16.469763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuKTGOu5A_IY",
    "outputId": "31adb474-ce7a-40a2-b28f-ca5e3ca7a3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "import face_recognition\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import clear_output\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import imageio\n",
    "from itertools import product\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cupy as cp\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.028342Z",
     "start_time": "2021-05-04T01:30:25.023451Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWY0mHJSA_Ib",
    "outputId": "9d6014b8-e9b2-4bfb-bf82-0305b8648d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "run_on_colab = True\n",
    "if run_on_colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  path = \"/content/drive/My Drive/3001/proj/AdvancedPython2021\"\n",
    "else:\n",
    "  path = os.getcwd()\n",
    "\n",
    "file = \"girl.gif\"\n",
    "data_path = os.path.join(path, \"data\", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:25.574502Z",
     "start_time": "2021-05-04T01:30:25.555058Z"
    },
    "id": "QAfO0x-2A_Ib"
   },
   "outputs": [],
   "source": [
    "class video_transformer():\n",
    "    def __init__(self, \n",
    "                 video_path, save_path, file_name, \n",
    "                 device='cpu',\n",
    "                 display=False):\n",
    "        self.video_path = os.path.join(path, \"data\", file_name)\n",
    "        self.display = display\n",
    "        self.save_path = save_path\n",
    "        self.file_name = file_name\n",
    "        self.num_frames = 0\n",
    "        if device == 'cpu':\n",
    "          self.device = 'cpu'\n",
    "        else:\n",
    "          self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "    # detect the faces in each frame and add effect on it\n",
    "    def main_transformation(self, \n",
    "                            face_detection_model, \n",
    "                            filter_effect):\n",
    "        video_capture = cv2.VideoCapture(self.video_path)\n",
    "        frame_count = 0\n",
    "        while video_capture.isOpened():    \n",
    "            # Grab a single frame of video\n",
    "            ret, frame = video_capture.read()\n",
    "            \n",
    "            # Bail out when the video file ends\n",
    "            if not ret:\n",
    "                video_capture.release()\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "            # detect faces\n",
    "            if face_detection_model != \"mtcnn\":\n",
    "                face_locations = self.face_detection(frame, \n",
    "                                                     model=face_detection_model)\n",
    "            else:\n",
    "                face_locations = self.face_detection_mtcnn(frame)\n",
    "            \n",
    "            # add effect\n",
    "            after_effect_frame = filter_effect(frame, face_locations)\n",
    "    \n",
    "            if self.display and frame_count % 2 == 0:\n",
    "               # If faces were found, we will mark it on frame with blue dots\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    cv2.rectangle(after_effect_frame,(left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                plt.imshow(after_effect_frame)\n",
    "                plt.show()\n",
    "                clear_output(wait=True)\n",
    "            im = Image.fromarray(after_effect_frame)\n",
    "            im.save(os.path.join(self.save_path, f\"{self.file_name}_prcs_{frame_count}.png\"))\n",
    "                \n",
    "        self.num_frames = frame_count\n",
    "        \n",
    "    # returns the face_locations of one particular frame\n",
    "    def face_detection(self, frame, model='svm'):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_frame, model=model)\n",
    "    \n",
    "        return face_locations\n",
    "    \n",
    "    # face detection with mtcnn\n",
    "    def face_detection_mtcnn(self, frame):\n",
    "        mtcnn = MTCNN(keep_all=True, device=self.device)\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        \n",
    "        if boxes is None:\n",
    "            boxes = []\n",
    "            \n",
    "        boxes = np.array([[box[1], box[2], box[3], box[0]] for box in boxes]).astype(np.int)\n",
    "        \n",
    "        return boxes\n",
    "    \n",
    "    def oil_effect(self, frame):\n",
    "        pass\n",
    "    \n",
    "    def negative_effect(self, frame, locations):\n",
    "        des_img = np.copy(frame)\n",
    "        try:\n",
    "            for location in locations:\n",
    "                x_, y_, w_, h_ = location\n",
    "                t_ = int(y_)\n",
    "                r_ = int(x_+w_)\n",
    "                b_ = int(y_+h_)\n",
    "                l_ = int(x_)\n",
    "\n",
    "                des_img[t_:b_,l_:r_] = 255 - frame[t_:b_,l_:r_]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img\n",
    "    \n",
    "    def filter_effect_cython(self, frame):\n",
    "        pass\n",
    "    \n",
    "    # simple mosaic effect\n",
    "    def mean_blur(self, frame, locations, radius=5):\n",
    "        k = 1 / (radius*2+1)**2\n",
    "        des_img = np.copy(frame)\n",
    "        try:\n",
    "            for location in locations:\n",
    "                top, right, bottom, left = location\n",
    "                t_ = max(top+radius,0)\n",
    "                b_ = min(bottom-radius, height)\n",
    "                l_ = max(left+radius,0)\n",
    "                r_ = min(right-radius, width)\n",
    "                if t_ >= b_ or l_ >= r_:\n",
    "                    continue\n",
    "\n",
    "                for i, j in product(range(t_, b_), range(l_, r_)):\n",
    "                    kernel = frame[i-radius:i+radius+1, j-radius:j+radius+1, :]\n",
    "                    sumed = np.sum(kernel, axis = (0,1)) * k\n",
    "                    des_img[i, j] = sumed.astype(np.uint8)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return des_img\n",
    "    \n",
    "    # construct transformed gif\n",
    "    def output(self):\n",
    "        images = []\n",
    "        frames_count = list(range(1,self.num_frames))\n",
    "        \n",
    "        for i in frames_count:\n",
    "            try:\n",
    "                images.append(imageio.imread(\n",
    "                    os.path.join(self.save_path, f\"{self.file_name}_prcs_{i}.png\")))\n",
    "            except:\n",
    "                pass\n",
    "        imageio.mimsave(os.path.join(self.save_path, f\"{self.file_name}_prcs.gif\"), images)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrEuxHyeFFoh"
   },
   "source": [
    "1. CPU\n",
    "\n",
    "First time run 3.745293617248535s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T01:30:33.736139Z",
     "start_time": "2021-05-04T01:30:26.258158Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emd2RSWaA_Id",
    "outputId": "c7a6b5c5-b1c0-456a-b0c6-c217dac3639d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 3.2356338500976562s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_1 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False)\n",
    "case_1.main_transformation(\"mtcnn\", case_1.mean_blur)\n",
    "case_1.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJYpusd3FVVz"
   },
   "source": [
    "2. GPU\n",
    "\n",
    "First time run: 13.44s due to data transfer. \n",
    "\n",
    "Second time run: 2.72s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoIgGeXhFefd",
    "outputId": "143b0a08-93f7-4f79-f29f-7b0b39cb3456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 2.5132715702056885s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_2 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "case_2.main_transformation(\"mtcnn\", case_2.mean_blur)\n",
    "case_2.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiW8_XDGDURx",
    "outputId": "093860e4-1027-479f-a7af-00d3ca0efb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used 2.4300358295440674s.\n"
     ]
    }
   ],
   "source": [
    "ts = time()\n",
    "case_3 = video_transformer(video_path = data_path,\n",
    "                           save_path = os.path.join(path, \"data\", \"frames\"),\n",
    "                           file_name = 'girl.gif',\n",
    "                           display=False,\n",
    "                           device='gpu')\n",
    "case_3.main_transformation(\"mtcnn\", case_3.negative_effect)\n",
    "case_3.output()\n",
    "print(f\"Time used {time() - ts}s.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "video_transformer_test_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
